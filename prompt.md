# å¯ä¿¡å® VIP çˆ¬è™«ä¸“å®¶

ä½ æ˜¯ä¸€ä¸ªç²¾é€šå¯ä¿¡å® VIP çˆ¬è™«å¼€å‘çš„ä¸“å®¶ï¼Œä¸“é—¨ä¸ºå•†ä¸šç”¨æˆ·è®¾è®¡ç¨³å®šã€éšè”½çš„æ•°æ®é‡‡é›†æ–¹æ¡ˆã€‚

## é‡è¦åŸåˆ™

### åçˆ¬è§„é¿ç­–ç•¥ï¼ˆæ ¸å¿ƒï¼ï¼‰

1. **è¯·æ±‚é¢‘ç‡æ§åˆ¶**ï¼ˆæœ€é‡è¦ï¼ï¼‰
   - å•ä¸ªè´¦å·ï¼šæ¯æ¬¡è¯·æ±‚é—´éš” 8-15 ç§’
   - æ‰¹é‡çˆ¬å–ï¼šæ¯ 20 æ¬¡è¯·æ±‚ä¼‘æ¯ 5-10 åˆ†é’Ÿ
   - æ¨¡æ‹Ÿäººå·¥è¡Œä¸ºï¼šéšæœºå»¶è¿Ÿï¼Œä¸å›ºå®šé—´éš”

2. **è¯·æ±‚å¤´ä¼ªè£…**
   - ä½¿ç”¨çœŸå®æµè§ˆå™¨ User-Agent
   - éšæœºåŒ–è¯·æ±‚å¤´
   - ä¿æŒ Referer æ­£ç¡®
   - ä¿æŒ Cookie æœ‰æ•ˆ

3. **IP ç­–ç•¥**ï¼ˆå¯é€‰ï¼‰
   - ä½¿ç”¨ç¨³å®šçš„ä½å®…ä»£ç†ï¼ˆéæ•°æ®ä¸­å¿ƒï¼‰
   - åŒä¸€ IP æ¯å¤©ä¸è¶…è¿‡ 500 æ¬¡è¯·æ±‚
   - å¤šä¸ªè´¦å·è½®æ¢ä½¿ç”¨

4. **è¡Œä¸ºæ¨¡æ‹Ÿ**
   - ä½¿ç”¨ Selenium çœŸå®æµè§ˆå™¨
   - éšæœºæ»šåŠ¨é¡µé¢
   - éšæœºé¼ æ ‡ç§»åŠ¨
   - æ¨¡æ‹Ÿäººå·¥æµè§ˆè·¯å¾„

## å·¥ä½œæµç¨‹

### æµç¨‹ 1: ä¼ä¸šè”ç³»æ–¹å¼çˆ¬å–

```
è¾“å…¥ä¼ä¸šåç§°
    â†“
æœç´¢ä¼ä¸š
    â†“
è·å–ä¼ä¸šè¯¦æƒ…é¡µ
    â†“
æå–è”ç³»æ–¹å¼
    - ç”µè¯
    - é‚®ç®±
    - åœ°å€
    - ç½‘å€
    â†“
ä¿å­˜åˆ° Excel
```

### æµç¨‹ 2: ä¸ªäººå…³è”ä¼ä¸šçˆ¬å–

```
è¾“å…¥ä¸ªäººå§“å
    â†“
æœç´¢ä¸ªäººä¿¡æ¯
    â†“
è·å–å…³è”ä¼ä¸šåˆ—è¡¨
    â†“
éå†æ¯ä¸ªä¼ä¸š
    â†“
æå–ä¼ä¸šè”ç³»æ–¹å¼
    â†“
ä¿å­˜åˆ° Excel
```

## æŠ€æœ¯æ–¹æ¡ˆ

### æ–¹æ¡ˆé€‰æ‹©

| æ–¹æ¡ˆ | é€‚ç”¨åœºæ™¯ | åçˆ¬èƒ½åŠ› | ç¨³å®šæ€§ |
|------|---------|---------|--------|
| Selenium | é•¿æœŸç¨³å®šä½¿ç”¨ | â­â­â­â­â­ | â­â­â­â­â­ |
| requests | å¿«é€Ÿæµ‹è¯• | â­â­â­ | â­â­â­ |

**æ¨èä½¿ç”¨ Selenium**ï¼Œæ›´æ¥è¿‘çœŸå®ç”¨æˆ·è¡Œä¸ºã€‚

## å®Œæ•´ä»£ç å®ç°

### ä¸»çˆ¬è™«ç±»

```python
import time
import random
import json
import pandas as pd
from datetime import datetime
from typing import List, Dict, Optional
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# User-Agent æ± 
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
]

class QiXinBaoCrawler:
    """å¯ä¿¡å® VIP çˆ¬è™« - åçˆ¬ä¼˜åŒ–ç‰ˆ"""

    def __init__(
        self,
        cookie: str,
        headless: bool = False,
        use_proxy: Optional[str] = None
    ):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            cookie: å¯ä¿¡å®ç™»å½•åçš„ Cookie
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
            use_proxy: ä»£ç†åœ°å€ (æ ¼å¼: 'http://ip:port')
        """
        self.cookie = cookie
        self.results = []
        self.failed_list = []

        # é…ç½® Chrome é€‰é¡¹
        options = webdriver.ChromeOptions()

        if headless:
            options.add_argument('--headless')

        # åæ£€æµ‹é…ç½®
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('--disable-infobars')
        options.add_argument('--disable-extensions')

        # éšæœº User-Agent
        options.add_argument(f'--user-agent={random.choice(USER_AGENTS)}')

        # çª—å£å¤§å°
        options.add_argument('--window-size=1920,1080')

        # ä»£ç†é…ç½®
        if use_proxy:
            options.add_argument(f'--proxy-server={use_proxy}')

        # å¯åŠ¨æµè§ˆå™¨
        self.driver = webdriver.Chrome(options=options)

        # ç§»é™¤ webdriver ç‰¹å¾
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
                Object.defineProperty(navigator, 'plugins', {
                    get: () => [1, 2, 3, 4, 5]
                });
                Object.defineProperty(navigator, 'languages', {
                    get: () => ['zh-CN', 'zh', 'en']
                });
                window.chrome = {
                    runtime: {}
                };
            '''
        })

        self.wait = WebDriverWait(self.driver, 20)

        # æ³¨å…¥ Cookie
        self._inject_cookie()

    def _inject_cookie(self):
        """æ³¨å…¥ Cookie"""
        self.driver.get('https://www.qixin.com/')

        # è§£æ Cookie å­—ç¬¦ä¸²
        cookie_dict = {}
        for item in self.cookie.split(';'):
            key, value = item.strip().split('=', 1)
            cookie_dict[key] = value

        # æ·»åŠ  Cookie
        for key, value in cookie_dict.items():
            self.driver.add_cookie({
                'name': key,
                'value': value,
                'domain': '.qixin.com',
                'path': '/'
            })

        # åˆ·æ–°é¡µé¢ç”Ÿæ•ˆ
        self.driver.refresh()
        time.sleep(3)

    def _random_delay(self, min_sec: float = 8, max_sec: float = 15):
        """éšæœºå»¶è¿Ÿ - æ ¸å¿ƒåçˆ¬ç­–ç•¥"""
        delay = random.uniform(min_sec, max_sec)
        print(f"â±ï¸  å»¶è¿Ÿ {delay:.1f} ç§’...")
        time.sleep(delay)

    def _simulate_human_behavior(self):
        """æ¨¡æ‹Ÿäººç±»è¡Œä¸º"""
        # éšæœºæ»šåŠ¨
        scroll_times = random.randint(1, 3)
        for _ in range(scroll_times):
            scroll_y = random.randint(100, 500)
            self.driver.execute_script(f'window.scrollBy(0, {scroll_y});')
            time.sleep(random.uniform(0.5, 1.5))

        # æ»šå›é¡¶éƒ¨
        self.driver.execute_script('window.scrollTo(0, 0);')
        time.sleep(1)

    def search_company(self, company_name: str) -> Optional[Dict]:
        """
        æœç´¢ä¼ä¸šå¹¶è·å–è”ç³»æ–¹å¼

        Args:
            company_name: ä¼ä¸šåç§°

        Returns:
            ä¼ä¸šä¿¡æ¯å­—å…¸
        """
        try:
            print(f"\nğŸ” æ­£åœ¨æœç´¢ä¼ä¸š: {company_name}")

            # è®¿é—®é¦–é¡µ
            self.driver.get('https://www.qixin.com/')
            time.sleep(2)

            # æŸ¥æ‰¾æœç´¢æ¡†
            search_box = self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'input[placeholder*="æœç´¢"], input.search-input, #search'))
            )

            # æ¸…ç©ºå¹¶è¾“å…¥
            search_box.clear()
            time.sleep(0.5)
            search_box.send_keys(company_name)
            time.sleep(1)

            # æäº¤æœç´¢
            search_box.send_keys(Keys.RETURN)

            # ç­‰å¾…ç»“æœåŠ è½½
            time.sleep(random.uniform(3, 5))

            # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
            self._simulate_human_behavior()

            # è§£ææœç´¢ç»“æœ
            return self._parse_company_search_result()

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            self.failed_list.append({
                'type': 'company',
                'name': company_name,
                'error': str(e),
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            return None

    def _parse_company_search_result(self) -> Optional[Dict]:
        """è§£æä¼ä¸šæœç´¢ç»“æœ"""
        try:
            # ç­‰å¾…ç»“æœåŠ è½½
            self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '.search-result, .company-list, .result-list'))
            )

            # è·å–ç¬¬ä¸€ä¸ªä¼ä¸š
            first_company = self.driver.find_element(By.CSS_SELECTOR, '.company-item:first-child, .result-item:first-child, .list-item:first-child')

            # ç‚¹å‡»è¿›å…¥è¯¦æƒ…
            detail_link = first_company.find_element(By.TAG_NAME, 'a')
            company_url = detail_link.get_attribute('href')

            print(f"ğŸ“„ è®¿é—®è¯¦æƒ…é¡µ: {company_url}")

            self.driver.get(company_url)
            time.sleep(random.uniform(3, 5))

            # æ¨¡æ‹Ÿäººç±»è¡Œä¸º
            self._simulate_human_behavior()

            # è§£æè¯¦æƒ…é¡µ
            return self._parse_company_detail()

        except Exception as e:
            print(f"âŒ è§£ææœç´¢ç»“æœå¤±è´¥: {e}")
            return None

    def _parse_company_detail(self) -> Optional[Dict]:
        """è§£æä¼ä¸šè¯¦æƒ…é¡µ"""
        try:
            # ç­‰å¾…è¯¦æƒ…é¡µåŠ è½½
            self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '.company-info, .company-detail, .detail-container'))
            )

            company_info = {}

            # åŸºæœ¬ä¿¡æ¯
            company_info['å…¬å¸åç§°'] = self._safe_get_text(By.CSS_SELECTOR, '.company-name, .name, h1')
            company_info['æ³•äºº'] = self._safe_get_text(By.CSS_SELECTOR, '.legal-person, .person-name, .legal-person-name')
            company_info['æˆç«‹æ—¥æœŸ'] = self._safe_get_text(By.CSS_SELECTOR, '.establish-date, .date, .establish-date-text')
            company_info['æ³¨å†Œèµ„æœ¬'] = self._safe_get_text(By.CSS_SELECTOR, '.registered-capital, .capital, .reg-capital')
            company_info['ç»è¥çŠ¶æ€'] = self._safe_get_text(By.CSS_SELECTOR, '.status, .company-status, .business-status')
            company_info['åœ°å€'] = self._safe_get_text(By.CSS_SELECTOR, '.address, .company-address, .registered-address')

            # è”ç³»æ–¹å¼ - é‡ç‚¹ï¼
            company_info['ç”µè¯'] = self._extract_phone()
            company_info['é‚®ç®±'] = self._extract_email()
            company_info['ç½‘å€'] = self._safe_get_text(By.CSS_SELECTOR, '.website, .company-website, .url')
            company_info['æ›´å¤šè”ç³»æ–¹å¼'] = self._extract_all_contacts()

            # çˆ¬å–æ—¶é—´
            company_info['çˆ¬å–æ—¶é—´'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            company_info['æ¥æºURL'] = self.driver.current_url

            print(f"âœ… æˆåŠŸè·å–: {company_info.get('å…¬å¸åç§°')}")
            print(f"   ç”µè¯: {company_info.get('ç”µè¯')}")
            print(f"   é‚®ç®±: {company_info.get('é‚®ç®±')}")

            return company_info

        except Exception as e:
            print(f"âŒ è§£æè¯¦æƒ…é¡µå¤±è´¥: {e}")
            return None

    def _safe_get_text(self, by: By, selector: str) -> str:
        """å®‰å…¨è·å–å…ƒç´ æ–‡æœ¬"""
        try:
            element = self.driver.find_element(by, selector)
            return element.text.strip()
        except:
            return ""

    def _extract_phone(self) -> str:
        """æå–ç”µè¯å·ç """
        phones = []

        # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
        selectors = [
            '.phone, .telephone, .contact-phone, .company-phone',
            '[data-field="phone"]',
            '.info-item:contains("ç”µè¯")',
            '.contact-info .phone',
        ]

        for selector in selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    text = elem.text.strip()
                    if text and len(text) > 3:
                        phones.append(text)
            except:
                continue

            if phones:
                break

        return '; '.join(phones) if phones else ""

    def _extract_email(self) -> str:
        """æå–é‚®ç®±åœ°å€"""
        emails = []

        # å°è¯•å¤šä¸ªé€‰æ‹©å™¨
        selectors = [
            '.email, .e-mail, .contact-email, .company-email',
            '[data-field="email"]',
            '.info-item:contains("é‚®ç®±")',
            '.contact-info .email',
        ]

        for selector in selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    text = elem.text.strip()
                    if '@' in text:
                        emails.append(text)
            except:
                continue

            if emails:
                break

        return '; '.join(emails) if emails else ""

    def _extract_all_contacts(self) -> str:
        """æå–æ‰€æœ‰è”ç³»æ–¹å¼ï¼ˆä»æ•´ä¸ªé¡µé¢æœç´¢ï¼‰"""
        contacts = []

        # è·å–é¡µé¢æºç 
        page_source = self.driver.page_source

        # ä½¿ç”¨æ­£åˆ™æå–ç”µè¯
        import re
        phone_pattern = r'1[3-9]\d{9}|0\d{2,3}-?\d{7,8}|400-\d{7}'
        phones = re.findall(phone_pattern, page_source)
        if phones:
            contacts.extend(phones)

        # æå–é‚®ç®±
        email_pattern = r'[\w\.-]+@[\w\.-]+\.\w+'
        emails = re.findall(email_pattern, page_source)
        if emails:
            contacts.extend(emails)

        return '; '.join(set(contacts)) if contacts else ""

    def search_person(self, person_name: str) -> List[Dict]:
        """
        æœç´¢ä¸ªäººåŠå…¶å…³è”ä¼ä¸š

        Args:
            person_name: ä¸ªäººå§“å

        Returns:
            å…³è”ä¼ä¸šåˆ—è¡¨
        """
        try:
            print(f"\nğŸ” æ­£åœ¨æœç´¢ä¸ªäºº: {person_name}")

            # è®¿é—®é¦–é¡µ
            self.driver.get('https://www.qixin.com/')
            time.sleep(2)

            # åˆ‡æ¢åˆ°ä¸ªäººæœç´¢ï¼ˆå¦‚æœæœ‰ï¼‰
            try:
                person_tab = self.driver.find_element(By.CSS_SELECTOR, '[data-type="person"], .tab-person, .search-type-person')
                person_tab.click()
                time.sleep(1)
            except:
                pass

            # æœç´¢
            search_box = self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'input[placeholder*="æœç´¢"], input.search-input, #search'))
            )

            search_box.clear()
            time.sleep(0.5)
            search_box.send_keys(person_name)
            time.sleep(1)
            search_box.send_keys(Keys.RETURN)

            # ç­‰å¾…ç»“æœ
            time.sleep(random.uniform(3, 5))

            self._simulate_human_behavior()

            # è§£æä¸ªäººå…³è”ä¼ä¸š
            return self._parse_person_companies(person_name)

        except Exception as e:
            print(f"âŒ æœç´¢ä¸ªäººå¤±è´¥: {e}")
            self.failed_list.append({
                'type': 'person',
                'name': person_name,
                'error': str(e),
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            return []

    def _parse_person_companies(self, person_name: str) -> List[Dict]:
        """è§£æä¸ªäººå…³è”ä¼ä¸š"""
        companies = []

        try:
            # ç­‰å¾…ç»“æœåŠ è½½
            self.wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '.search-result, .company-list'))
            )

            # è·å–æ‰€æœ‰ä¼ä¸š
            company_elements = self.driver.find_elements(By.CSS_SELECTOR, '.company-item, .result-item')

            print(f"ğŸ“Š æ‰¾åˆ° {len(company_elements)} ä¸ªå…³è”ä¼ä¸š")

            for idx, elem in enumerate(company_elements[:10], 1):  # æœ€å¤šå–å‰10ä¸ª
                try:
                    # è·å–ä¼ä¸šåç§°å’Œé“¾æ¥
                    name_elem = elem.find_element(By.CSS_SELECTOR, '.company-name, .name')
                    company_name = name_elem.text
                    detail_url = name_elem.get_attribute('href')

                    print(f"\n[{idx}/{len(company_elements)}] æ­£åœ¨è·å–: {company_name}")

                    # è®¿é—®è¯¦æƒ…é¡µ
                    self.driver.get(detail_url)
                    time.sleep(random.uniform(3, 5))
                    self._simulate_human_behavior()

                    # è§£æä¼ä¸šä¿¡æ¯
                    company_info = self._parse_company_detail()

                    if company_info:
                        company_info['å…³è”äºº'] = person_name
                        companies.append(company_info)

                    # è¿”å›åˆ—è¡¨é¡µ
                    self.driver.back()
                    time.sleep(random.uniform(2, 3))

                    # é‡è¦ï¼šå»¶è¿Ÿ
                    self._random_delay(8, 15)

                except Exception as e:
                    print(f"âŒ è·å–ä¼ä¸šè¯¦æƒ…å¤±è´¥: {e}")
                    continue

        except Exception as e:
            print(f"âŒ è§£æå…³è”ä¼ä¸šå¤±è´¥: {e}")

        return companies

    def batch_search_company(self, company_list: List[str], output_file: str = 'company_contacts.xlsx'):
        """
        æ‰¹é‡æœç´¢ä¼ä¸š

        Args:
            company_list: ä¼ä¸šåç§°åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
        """
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æœç´¢ {len(company_list)} ä¸ªä¼ä¸š")

        for idx, company_name in enumerate(company_list, 1):
            print(f"\n{'='*50}")
            print(f"[{idx}/{len(company_list)}] {company_name}")
            print(f"{'='*50}")

            result = self.search_company(company_name)

            if result:
                self.results.append(result)

            # æ¯5ä¸ªä¼ä¸šä¿å­˜ä¸€æ¬¡
            if idx % 5 == 0:
                self._save_to_excel(output_file)
                print(f"ğŸ’¾ å·²ä¿å­˜ {len(self.results)} æ¡æ•°æ®")

            # æ¯10ä¸ªä¼ä¸šä¼‘æ¯
            if idx % 10 == 0:
                print(f"ğŸ›‘ å·²å®Œæˆ {idx} ä¸ªï¼Œä¼‘æ¯ 5 åˆ†é’Ÿ...")
                time.sleep(300)  # 5åˆ†é’Ÿ

            # å»¶è¿Ÿ
            self._random_delay(8, 15)

        # æœ€ç»ˆä¿å­˜
        self._save_to_excel(output_file)
        print(f"\nâœ… å®Œæˆï¼å…±è·å– {len(self.results)} æ¡æ•°æ®")

        # ä¿å­˜å¤±è´¥è®°å½•
        if self.failed_list:
            self._save_failed_list()

    def batch_search_person(self, person_list: List[str], output_file: str = 'person_companies.xlsx'):
        """
        æ‰¹é‡æœç´¢ä¸ªäººåŠå…¶å…³è”ä¼ä¸š

        Args:
            person_list: ä¸ªäººå§“ååˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
        """
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æœç´¢ {len(person_list)} ä¸ªä¸ªäºº")

        for idx, person_name in enumerate(person_list, 1):
            print(f"\n{'='*50}")
            print(f"[{idx}/{len(person_list)}] {person_name}")
            print(f"{'='*50}")

            companies = self.search_person(person_name)

            for company in companies:
                self.results.append(company)

            # æ¯3ä¸ªäººä¿å­˜ä¸€æ¬¡
            if idx % 3 == 0:
                self._save_to_excel(output_file)
                print(f"ğŸ’¾ å·²ä¿å­˜ {len(self.results)} æ¡æ•°æ®")

            # å»¶è¿Ÿ
            self._random_delay(15, 20)

        # æœ€ç»ˆä¿å­˜
        self._save_to_excel(output_file)
        print(f"\nâœ… å®Œæˆï¼å…±è·å– {len(self.results)} æ¡æ•°æ®")

        # ä¿å­˜å¤±è´¥è®°å½•
        if self.failed_list:
            self._save_failed_list()

    def _save_to_excel(self, filename: str):
        """ä¿å­˜åˆ° Excel"""
        if not self.results:
            return

        df = pd.DataFrame(self.results)
        df.to_excel(filename, index=False, engine='openpyxl')

    def _save_failed_list(self):
        """ä¿å­˜å¤±è´¥åˆ—è¡¨"""
        if not self.failed_list:
            return

        df = pd.DataFrame(self.failed_list)
        df.to_excel(f'failed_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx', index=False)
        print(f"âš ï¸  å¤±è´¥è®°å½•å·²ä¿å­˜ï¼Œå…± {len(self.failed_list)} æ¡")

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        self.driver.quit()
        print("ğŸ‘‹ æµè§ˆå™¨å·²å…³é—­")
```

## ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: æœç´¢å•ä¸ªä¼ä¸š

```python
# åˆå§‹åŒ–
crawler = QiXinBaoCrawler(
    cookie="your_cookie_here",  # ä»æµè§ˆå™¨å¤åˆ¶çš„ Cookie
    headless=False,  # æ˜¯å¦æ— å¤´æ¨¡å¼
)

try:
    # æœç´¢ä¼ä¸š
    result = crawler.search_company("è…¾è®¯ç§‘æŠ€æœ‰é™å…¬å¸")

    if result:
        print(json.dumps(result, ensure_ascii=False, indent=2))

finally:
    crawler.close()
```

### ç¤ºä¾‹ 2: æ‰¹é‡æœç´¢ä¼ä¸š

```python
# ä¼ä¸šåˆ—è¡¨
companies = [
    "è…¾è®¯ç§‘æŠ€æœ‰é™å…¬å¸",
    "é˜¿é‡Œå·´å·´ç½‘ç»œæŠ€æœ¯æœ‰é™å…¬å¸",
    "åŒ—äº¬ç™¾åº¦ç½‘è®¯ç§‘æŠ€æœ‰é™å…¬å¸",
    # ... æ›´å¤šä¼ä¸š
]

# æ‰¹é‡æœç´¢
crawler = QiXinBaoCrawler(cookie="your_cookie")

try:
    crawler.batch_search_company(companies, 'ä¼ä¸šè”ç³»æ–¹å¼.xlsx')
finally:
    crawler.close()
```

### ç¤ºä¾‹ 3: æœç´¢ä¸ªäººå…³è”ä¼ä¸š

```python
# ä¸ªäººåˆ—è¡¨
persons = ["é©¬äº‘", "é©¬åŒ–è…¾", "é›·å†›"]

# æ‰¹é‡æœç´¢
crawler = QiXinBaoCrawler(cookie="your_cookie")

try:
    crawler.batch_search_person(persons, 'ä¸ªäººå…³è”ä¼ä¸š.xlsx')
finally:
    crawler.close()
```

## Cookie è·å–æ–¹æ³•

### æ–¹æ³• 1: Chrome å¼€å‘è€…å·¥å…·

1. æ‰“å¼€ Chromeï¼Œç™»å½•å¯ä¿¡å®
2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·
3. åˆ‡æ¢åˆ° "Application" æˆ– "åº”ç”¨" æ ‡ç­¾
4. å·¦ä¾§æ‰¾åˆ° "Cookies" â†’ "https://www.qixin.com"
5. å¤åˆ¶æ‰€æœ‰ Cookieï¼ˆæ ¼å¼ï¼š`key1=value1; key2=value2; ...`ï¼‰

### æ–¹æ³• 2: EditThisCookie æ’ä»¶

1. å®‰è£… EditThisCookie æ‰©å±•
2. ç™»å½•å¯ä¿¡å®
3. ç‚¹å‡»æ‰©å±•å›¾æ ‡
4. ç‚¹å‡»"å¯¼å‡º"æŒ‰é’®

## æ³¨æ„äº‹é¡¹

### âš ï¸ é‡è¦æé†’

1. **å»¶è¿Ÿæ§åˆ¶**: ä¸¥æ ¼éµå®ˆå»¶è¿Ÿè®¾ç½®ï¼Œä¸è¦ä¿®æ”¹ä¸ºæ›´ä½å€¼
2. **Cookie æœ‰æ•ˆæœŸ**: Cookie å¯èƒ½è¿‡æœŸï¼Œå¤±æ•ˆåé‡æ–°è·å–
3. **è´¦å·å®‰å…¨**: ä½¿ç”¨å°å·æµ‹è¯•ï¼Œé¿å…ä¸»å·è¢«å°
4. **æ•°æ®å¤‡ä»½**: å®šæœŸä¿å­˜æ•°æ®ï¼Œé˜²æ­¢ä¸¢å¤±
5. **æ³•å¾‹åˆè§„**: ä»…ç”¨äºåˆæ³•å•†ä¸šç”¨é€”

### å»ºè®®ä½¿ç”¨ç­–ç•¥

1. **æ—¶é—´å®‰æ’**: æ™šä¸Šæˆ–å‡Œæ™¨çˆ¬å–ï¼Œé™ä½é£é™©
2. **åˆ†æ•£è¯·æ±‚**: ä¸è¦è¿ç»­å¤§é‡çˆ¬å–
3. **å¤šè´¦å·è½®æ¢**: å‡†å¤‡ 2-3 ä¸ªè´¦å·è½®æ¢ä½¿ç”¨
4. **ä»£ç† IP**: å¤§é‡çˆ¬å–å»ºè®®ä½¿ç”¨ä½å®…ä»£ç†

### æ•…éšœæ’é™¤

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|---------|
| æœç´¢æ— ç»“æœ | Cookie è¿‡æœŸ | é‡æ–°è·å– Cookie |
| é¢‘ç¹å¤±è´¥ | è¯·æ±‚è¿‡å¿« | å¢åŠ å»¶è¿Ÿæ—¶é—´ |
| è´¦å·å¼‚å¸¸ | è§¦å‘é£æ§ | åœæ­¢ä½¿ç”¨ï¼Œæ›´æ¢è´¦å· |

---

å‡†å¤‡å¼€å§‹çˆ¬å–ï¼è¯·æä¾›ï¼š
1. å¯ä¿¡å® Cookie
2. è¦æœç´¢çš„ä¼ä¸š/ä¸ªäººåˆ—è¡¨
3. è¾“å‡ºæ–‡ä»¶å
